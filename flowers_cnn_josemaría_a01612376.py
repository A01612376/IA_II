# -*- coding: utf-8 -*-
"""Flowers CNN Josemaría A01612376.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tdZYykKZf-AldtoNPGdSLiLl7Qe-KOhU

#**Flowers CNN Josemaría A01612376**
"""

from google.colab import drive

drive.mount("/content/gdrive")
!pwd  # show current path

# Commented out IPython magic to ensure Python compatibility.
# %cd "/content/gdrive/MyDrive/AI/flowers"
!ls  # show current directory

"""##Importación de bibliotecas

Algunas de las bibliotecas incluyen warnings para gestionar advertencias, numpy y pandas para manipulación de datos, matplotlib y seaborn para visualización, y varias bibliotecas relacionadas con aprendizaje profundo, como Keras y TensorFlow.
"""

# Commented out IPython magic to ensure Python compatibility.
# Ignore the warnings
import warnings
warnings.filterwarnings('always')
warnings.filterwarnings('ignore')

# Data visualisation and manipulation
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib import style
import seaborn as sns

# Configure
# Sets matplotlib to inline and displays graphs below the corressponding cell.
# %matplotlib inline
style.use('fivethirtyeight')
sns.set(style='whitegrid',color_codes=True)

# Model selection
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold
from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,roc_curve,roc_auc_score
from sklearn.model_selection import GridSearchCV
from sklearn.preprocessing import LabelEncoder

# Preprocess.
from keras.preprocessing.image import ImageDataGenerator

# Dl libraries
from keras import backend as K
from keras.models import Sequential
from keras.layers import Dense
from keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop
from keras.utils import to_categorical

# Specifically for cnn
from keras.layers import Dropout, Flatten,Activation
from keras.layers import Conv2D, MaxPooling2D, BatchNormalization

import tensorflow as tf
import random as rn

# Specifically for manipulating zipped images and getting numpy arrays of pixel values of images.
import cv2
import numpy as np
from tqdm import tqdm
import os
from random import shuffle
from zipfile import ZipFile
from PIL import Image

"""##Almacenamiento de imágenes

X=[] y Z=[]: Listas vacías que se utilizarán para almacenar los datos de las imágenes y sus etiquetas correspondientes. X se usará para almacenar las imágenes, y Z se utilizará para almacenar las etiquetas de las flores.

IMG_SIZE=150: Tamaño al que se redimensionarán todas las imágenes antes de cargarlas en el modelo. Todas las imágenes se redimensionarán a un tamaño cuadrado de 150x150 píxeles.

FLOWER_DAISY_DIR, FLOWER_SUNFLOWER_DIR, FLOWER_TULIP_DIR, FLOWER_DANDI_DIR, y FLOWER_ROSE_DIR: Estas son variables que almacenan las rutas de los directorios que contienen las imágenes de diferentes tipos de flores.
"""

X=[]
Z=[]
IMG_SIZE=150
FLOWER_DAISY_DIR='/content/gdrive/MyDrive/AI/flowers/daisy'
FLOWER_SUNFLOWER_DIR='/content/gdrive/MyDrive/AI/flowers/sunflower'
FLOWER_TULIP_DIR='/content/gdrive/MyDrive/AI/flowers/tulip'
FLOWER_DANDI_DIR='/content/gdrive/MyDrive/AI/flowers/dandelion'
FLOWER_ROSE_DIR='/content/gdrive/MyDrive/AI/flowers/rose'

"""Función para asignar etiquetas a las imágenes de flores. Aquí está la explicación de la función:"""

def assign_label(img,flower_type):
    return flower_type

"""Función para procesar imágenes las imágenes (especificado por flower_type y ubicado en el directorio DIR). Para cada imagen, se asigna una etiqueta, se redimensiona a un tamaño común y se almacena tanto la imagen como su etiqueta en las listas X y Z. Estas listas se utilizarán posteriormente para el entrenamiento del modelo. La función tqdm se utiliza para mostrar una barra de progreso durante el procesamiento de las imágenes."""

def make_train_data(flower_type,DIR):
    for img in tqdm(os.listdir(DIR)):
        label=assign_label(img,flower_type)
        path = os.path.join(DIR,img)
        img = cv2.imread(path,cv2.IMREAD_COLOR)
        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))

        X.append(np.array(img))
        Z.append(str(label))

make_train_data('Daisy',FLOWER_DAISY_DIR)
print(len(X))

make_train_data('Sunflower',FLOWER_SUNFLOWER_DIR)
print(len(X))

make_train_data('Tulip',FLOWER_TULIP_DIR)
print(len(X))

make_train_data('Dandelion',FLOWER_DANDI_DIR)
print(len(X))

make_train_data('Rose',FLOWER_ROSE_DIR)
print(len(X))

"""Muestra con selección aleatoria de imágenes de flores procesadas en una cuadrícula de 5 filas por 2 columnas."""

fig,ax=plt.subplots(5,2)
fig.set_size_inches(15,15)
for i in range(5):
    for j in range (2):
        l=rn.randint(0,len(Z))
        ax[i,j].imshow(X[l])
        ax[i,j].set_title('Flower: '+Z[l])

plt.tight_layout()

"""Preparación de los datos para el entrenamiento del modelo. Las etiquetas se codifican numéricamente, se convierten en formato categórico, las imágenes se convierten en arreglos NumPy y se normalizan para asegurar que estén en el rango adecuado antes de alimentarlas al modelo."""

le=LabelEncoder()
Y=le.fit_transform(Z)
Y=to_categorical(Y,5)
X=np.array(X)
X=X/255

"""Se divide el conjunto de datos en conjuntos de train y test."""

x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.25,random_state=42)

"""Se establecen las semillas aleatorias para diferentes bibliotecas. Al fijar las semillas, se asegura de que los mismos números aleatorios se utilicen en cada ejecución, lo que facilita la comparación de resultados y la depuración de problemas."""

np.random.seed(42)
rn.seed(42)
tf.random.set_seed(42)

"""El modelo posee una arquitectura de CNN, consta de capas convolucionales y de max pooling intercaladas con capas completamente conectadas. Las capas convolucionales se utilizan para extraer características de las imágenes, y las capas de max pooling reducen la resolución espacial. El modelo se entrena para clasificar las imágenes en una de las cinco clases de flores utilizando la capa final de salida con activación softmax."""

model = Sequential()
model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same',activation ='relu', input_shape = (150,150,3)))
model.add(MaxPooling2D(pool_size=(2,2)))


model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',activation ='relu'))
model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))


model.add(Conv2D(filters =96, kernel_size = (3,3),padding = 'Same',activation ='relu'))
model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))

model.add(Conv2D(filters = 96, kernel_size = (3,3),padding = 'Same',activation ='relu'))
model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))

model.add(Flatten())
model.add(Dense(512))
model.add(Activation('relu'))
model.add(Dense(5, activation = "softmax"))

"""Se configuran los hiperparámetros del tamaño del lote y el número de épocas de entrenamiento, y se establece un callback (ReduceLROnPlateau) que se utilizará para ajustar la tasa de aprendizaje durante el entrenamiento del modelo. La reducción de la tasa de aprendizaje es útil para permitir un entrenamiento más preciso y estable a medida que el modelo se acerca a la convergencia."""

batch_size=128
epochs=50

from keras.callbacks import ReduceLROnPlateau
red_lr= ReduceLROnPlateau(monitor='val_acc',patience=3,verbose=1,factor=0.1)

"""Se aplican diversas transformaciones aleatorias a las imágenes de train, lo que ayuda a aumentar la variabilidad de los datos y mejora la capacidad del modelo para generalizar a nuevas imágenes."""

datagen = ImageDataGenerator(
        featurewise_center=False,  # set input mean to 0 over the dataset
        samplewise_center=False,  # set each sample mean to 0
        featurewise_std_normalization=False,  # divide inputs by std of the dataset
        samplewise_std_normalization=False,  # divide each input by its std
        zca_whitening=False,  # apply ZCA whitening
        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)
        zoom_range = 0.1, # Randomly zoom image
        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)
        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)
        horizontal_flip=True,  # randomly flip images
        vertical_flip=False)  # randomly flip images


datagen.fit(x_train)

"""Se compila el modelo de la CNN antes de comenzar el proceso de entrenamiento."""

model.compile(optimizer=Adam(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])

model.summary()

"""Proceso de entrenamiento, donde el modelo ajustará sus pesos y bias utilizando los datos de train y calculará la pérdida y las métricas en los datos de train y validación en cada época. History captura esta información y se utiliza posteriormente para visualizar y analizar el progreso del entrenamiento, como la evolución de la pérdida y la precisión a lo largo de las épocas."""

History = model.fit_generator(datagen.flow(x_train,y_train, batch_size=batch_size),
                              epochs = epochs, validation_data = (x_test,y_test),
                              verbose = 1, steps_per_epoch=x_train.shape[0] // batch_size)

plt.plot(History.history['loss'])
plt.plot(History.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.legend(['train', 'test'])
plt.show()

plt.plot(History.history['accuracy'])
plt.plot(History.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epochs')
plt.legend(['train', 'test'])
plt.show()

"""Se calculan las predicciones del modelo en el conjunto de validación y luego determina la clase predicha para cada imagen en el conjunto de test. Estas predicciones se utilizarán más adelante para evaluar el rendimiento del modelo y generar métricas de evaluación."""

pred=model.predict(x_test)
pred_digits=np.argmax(pred,axis=1)

""" Se recopilan los índices de las imágenes en el conjunto de validación que fueron clasificadas correctamente (prop_class) y las que fueron clasificadas incorrectamente (mis_class) por el modelo."""

i=0
prop_class=[]
mis_class=[]

for i in range(len(y_test)):
    if(np.argmax(y_test[i])==pred_digits[i]):
        prop_class.append(i)
    if(len(prop_class)==8):
        break

i=0
for i in range(len(y_test)):
    if(not np.argmax(y_test[i])==pred_digits[i]):
        mis_class.append(i)
    if(len(mis_class)==8):
        break

"""Se muestran ejemplos de imágenes que el modelo ha clasificado **correctamente** en el conjunto de validación. Los títulos de las imágenes incluyen la clase predicha y la clase real de la imagen."""

warnings.filterwarnings('always')
warnings.filterwarnings('ignore')

count = 0
fig, ax = plt.subplots(4, 2)
fig.set_size_inches(15, 15)
for i in range(4):
    for j in range(2):
        if count < len(prop_class):
            ax[i, j].imshow(x_test[prop_class[count]])
            predicted_label = le.inverse_transform([pred_digits[prop_class[count]]])[0]
            actual_label = le.inverse_transform([np.argmax(y_test[prop_class[count]])])[0]
            ax[i, j].set_title(f"Predicted Flower: {predicted_label}\nActual Flower: {actual_label}")
        count += 1

plt.tight_layout()

"""Se muestran ejemplos de imágenes que el modelo ha clasificado **incorrectamente** en el conjunto de validación. Los títulos de las imágenes incluyen la clase predicha y la clase real de la imagen."""

warnings.filterwarnings('always')
warnings.filterwarnings('ignore')

count = 0
fig, ax = plt.subplots(4, 2)
fig.set_size_inches(15, 15)
for i in range(4):
    for j in range(2):
        if count < len(mis_class):
            ax[i, j].imshow(x_test[mis_class[count]])
            predicted_label = le.inverse_transform([pred_digits[mis_class[count]]])[0]
            actual_label = le.inverse_transform([np.argmax(y_test[mis_class[count]])])[0]
            ax[i, j].set_title(f"Predicted Flower: {predicted_label}\nActual Flower: {actual_label}")
        count += 1

plt.tight_layout()